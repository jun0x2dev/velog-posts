---
title: "Redis의 정석: 인메모리 데이터 저장소의 활용 패턴과 분산 락 (Deep Dive)"
series_order: 7
description: "단순 캐시를 넘어 싱글 스레드의 비밀, 캐시 전략, 루아 스크립트, 그리고 캐시 스탬피드 대처법까지 실무 핵심 기술을 파헤칩니다."
date: 2026-02-10
update: 2026-02-11
tags: [Database, Redis, NoSQL, Cache, 분산락, Cluster, Lua_Script, 캐시_스탬피드]
---

# Redis의 정석: 인메모리 데이터 저장소의 활용 패턴과 분산 락

## 서론
사용자가 갑자기 몰리는 이벤트 시간, 평소라면 평온하던 우리 서버가 갑자기 비명을 지르기 시작합니다. 범인은 대부분 **데이터베이스(DB)**입니다. 디스크에 데이터를 저장하는 DB는 아무리 최적화를 해도 물리적인 속도의 한계가 있기 때문이죠. 

이때 우리에게 필요한 것이 바로 **Redis(Remote Dictionary Server)**입니다. 모든 데이터를 메모리에 담아두고 빠르게 응답하는 이 친구는, 이제 백엔드 아키텍처에서 선택이 아닌 필수입니다. 하지만 "레디스는 그냥 메모리에 저장해서 빠른 거 아니야?"라고만 생각하셨다면 오산입니다. 오늘은 레디스가 왜 '진짜' 빠른지, 그리고 실무에서 우리를 괴롭히는 문제들을 어떻게 해결하는지 딥다이브 해보겠습니다.

![Redis 고속 데이터 처리 아키텍처](/images/04_Database/Redis_Basics_and_Patterns/redis_speed_architecture.png)
*인메모리 기반의 데이터 저장과 효율적인 I/O 처리로 극강의 응답 속도를 보장하는 Redis의 내부 아키텍처입니다.*

## 본론

### 1. 싱글 스레드인데 왜 이렇게 빠를까? (I/O Multiplexing)
레디스는 싱글 스레드로 동작합니다. "요즘 세상에 멀티 코어를 안 쓴다고?"라며 의구심이 들 수 있지만, 바로 그 단순함이 레디스 속도의 비결입니다.

- **컨텍스트 스위칭 제로**: 멀티 스레드처럼 스레드끼리 자원을 다투거나(Lock), 주도권을 주고받는 비용이 전혀 없습니다.
- **I/O Multiplexing (Reactor Pattern)**: 레디스는 한 명의 직원이 수만 명의 손님을 받는 맛집과 같습니다. 하지만 이 직원은 손님이 메뉴를 고민하는 동안 멍하니 기다리지 않습니다. **epoll** 같은 시스템 콜을 이용해 '준비된 손님'의 요청만 가차 없이 처리하죠.
- **Redis 6.0+ Threaded I/O**: 이제는 I/O 읽기/쓰기에 한해 멀티 스레드를 도입했습니다. 하지만 핵심 로직은 여전히 싱글 스레드라는 점! 여전히 `KEYS *` 같은 무거운 명령은 금기사항입니다.
- **Big Key 주의보**: 아무리 빨라도 하나의 Key가 수백 MB를 차지하면, 그걸 읽거나 지우는 동안 레디스 전체가 멈춥니다. 큰 데이터는 쪼개서 저장하는 습관이 필요합니다.

---

### 2. 자료구조의 꽃: Sorted Set (ZSet)과 Skip List
레디스가 단순한 Key-Value 저장소를 넘어 '데이터 구조 서버'로 불리는 이유는 강력한 자료구조들 덕분입니다. 그중에서도 **Sorted Set(ZSet)**은 실시간 랭킹 시스템의 치트키입니다.

- **왜 빠른가? (Skip List)**: ZSet은 내부적으로 **Skip List**와 **Hash Table**을 함께 사용합니다. 일반적인 Linked List에서 원하는 요소를 찾으려면 처음부터 다 뒤져야 하지만, Skip List는 중간중간 '건너뛰기' 할 수 있는 인덱스를 두어 `O(logN)`의 속도로 데이터를 찾아냅니다. 
- **활용 사례**: 수백만 명의 유저 중 내 순위를 실시간으로 계산해야 할 때, ZSet의 `ZREVRANK` 명령 하나면 끝납니다.

---

### 3. 캐시 배치 전략: 정답은 없다, 상황만 있을 뿐
레디스를 어디에 두느냐에 따라 시스템의 운명이 결정됩니다.

| 전략 | 방식 | 장점 | 단점 |
| :--- | :--- | :--- | :--- |
| **Look Aside** | 앱이 캐시 먼저 확인, 없으면 DB 조회 후 캐시 저장 | 반복 조회 성능 우수 | 첫 조회 시 느림, DB-캐시 정합성 문제 |
| **Write Through** | DB 저장 시 캐시에도 동시 저장 | 캐시 데이터 최신성 보장 | 쓰기 성능 저하, 안 쓰는 데이터도 캐싱 |
| **Write Back** | 캐시에만 먼저 저장 후 나중에 모아서 DB 반영 | 쓰기 성능 극대화 | 레디스 장애 시 데이터 유실 위험 |

- **실무 팁**: 대부분의 웹 서비스는 **Look Aside** 패턴을 기본으로 가져가되, 정합성이 중요한 데이터는 TTL(만료 시간)을 짧게 설정하는 식으로 타협점을 찾더라고요!

---

### 4. 메모리가 가득 차면? 데이터 제거 정책 (Eviction)
레디스는 무한한 공간이 아닙니다. 설정한 `maxmemory`에 도달하면 누군가는 쫓겨나야 합니다. 이때 레디스의 정책(`maxmemory-policy`)이 중요합니다.

1.  **LRU (Least Recently Used)**: 가장 오랫동안 안 쓴 녀석을 내쫓습니다. (가장 무난합니다.)
2.  **LFU (Least Frequently Used)**: 가장 적게 사용된 녀석을 보냅니다. 최근에 들어왔어도 인기가 없으면 바로 퇴출입니다.
3.  **Volatile-TTL**: 만료 시간이 가장 임박한 녀석부터 정리합니다.

---

### 5. 원자성 끝판왕: 루아 스크립트 (Lua Scripting)
분산 시스템에서 여러 명령을 '한 번에, 끊김 없이' 실행하고 싶을 때가 있습니다. 레디스 트랜잭션(`MULTI/EXEC`)도 있지만, 더 강력한 무기는 바로 **루아 스크립트**입니다.

- **Atomicity**: 스크립트가 실행되는 동안 다른 명령은 끼어들 수 없습니다.
- **네트워크 비용 감소**: 여러 번 왔다 갔다 할 명령을 한 번에 묶어서 보낼 수 있습니다.

```lua
-- 재고 차감 루아 스크립트 예시
local stock = redis.call('get', KEYS[1])
if tonumber(stock) > 0 then
    redis.call('decr', KEYS[1])
    return 1
else
    return 0
end
```
**컴퓨터의 평**: "중간에 누가 가로챌 걱정 없으니 마음이 편안하네요. 하지만 스크립트가 너무 길어지면 제가 멈출 수도 있으니 조심하세요!"

---

### 6. 꺼진 불도 다시 보자: 영속성(Persistence) 전략
메모리는 전원이 꺼지면 모든 게 사라지는 휘발성 자원입니다. "레디스가 죽어도 내 소중한 데이터는 살려야겠다"면 두 가지 옵션 중 선택해야 합니다.

1.  **RDB (Snapshotting)**: 특정 시점의 메모리 전체를 스냅샷 찍듯 디스크에 저장합니다. 파일 사이즈가 작고 복구가 빠르지만, 스냅샷 사이의 공백기 데이터는 유실될 수 있습니다. (마치 게임의 세이브 포인트와 같습니다!)
2.  **AOF (Append Only File)**: 모든 쓰기 명령을 로그로 남깁니다. 데이터 유실은 거의 없지만, 파일이 무지막지하게 커지고 복구 속도가 느립니다.
- **실무 권장**: 보통은 두 방식을 혼합하여 사용합니다. RDB로 전체적인 복구 속도를 챙기고, AOF로 최신 데이터를 보존하는 식이죠.

---

### 7. 실무 트러블슈팅: 캐시 스탬피드 (Cache Stampede)
인기 연예인의 게시물 캐시가 딱 만료되는 순간, 수십만 명의 사용자가 동시에 DB로 달려가는 현상을 **캐시 스탬피드** 혹은 **Thundering Herd**라고 합니다. 이때 DB는 그대로 기절해버립니다.

- **해결책 (PER 알고리즘)**: 캐시가 만료되기 직전에 확률적으로 미리 갱신하는 기법입니다. 
- **간단한 방법**: 캐시 만료 시간을 고정하지 않고 `TTL + Random(10초)`처럼 약간의 노이즈를 주어 만료 시점을 분산시키는 것만으로도 큰 효과를 볼 수 있습니다.

---

### 8. 분산 락(Distributed Lock)과 Redisson
여러 서버가 하나의 자원을 놓고 경쟁할 때, 레디스를 중재자로 세웁니다.

- **Redisson의 위엄**: `SETNX`로 구현하면 스핀 락(Spin Lock) 때문에 레디스가 고생하지만, **Redisson**은 Pub/Sub 방식을 써서 락이 해제될 때까지 기다렸다가 알려줍니다. 레디스의 부하를 획기적으로 줄여주죠.

```java
RLock lock = redisson.getLock("event_lock");
try {
    // 락 획득 시도 (최대 5초 대기, 1초 후 자동 해제)
    if (lock.tryLock(5, 1, TimeUnit.SECONDS)) {
        // 한 명만 성공해야 하는 로직 수행
    }
} finally {
    // 현재 스레드가 락을 가지고 있는 경우에만 해제 (실무 필수 체크!)
    if (lock.isHeldByCurrentThread()) {
        lock.unlock();
    }
}
```

---

### 9. 실무 운영의 핵심: 고가용성(HA)
아무리 코드가 완벽해도 서버가 죽으면 끝입니다. 실무 운영 환경에서는 장애 조치를 위한 **Sentinel**이나 데이터 분산을 위한 **Cluster** 구성을 반드시 고려해야 합니다. 서비스의 규모와 가용성 요구 수준에 맞춰 적절한 아키텍처를 선택하는 안목이 필요합니다.

## 결론 및 요약 / 회고
레디스는 단순한 '빨라지는 요술 상자'가 아닙니다.
- **I/O Multiplexing** 원리를 이해하고 무거운 명령을 피하세요.
- 비즈니스 성격에 맞는 **캐시 전략**과 **Eviction 정책**을 선택하세요.
- **루아 스크립트**와 **Redisson**으로 동시성 문제를 우아하게 해결하세요.

메모리는 비싼 자원입니다. 모든 데이터를 다 넣으려 하기보다, 꼭 필요한 데이터만 선별해서 관리하는 설계가 고수의 한 끗 차이더라고요!

## 참고 자료
- [Redis Documentation: Client-side caching](https://redis.io/docs/manual/client-side-caching/)
- [High Scalability: Redis Sentinel & Cluster](http://highscalability.com/)
- [Redisson Official Guide: Distributed locks](https://redisson.org/docs/data-and-services/locks-and-synchronizers/)

---
